{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ea696c-a35d-46ea-b2ec-64df5e0f7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9b38e-70bf-4088-81cd-1fcf17752b35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3127de9-0cbc-4e6c-a9f7-159ecbef6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = \"C:/Users/May/Desktop/SURA24/datasets/1\"\n",
    "dataset_1_jet = \"C:/Users/May/Desktop/SURA24/datasets/1/cmapjet\"\n",
    "dataset_1_brg = \"C:/Users/May/Desktop/SURA24/datasets/1/cmapbrg\"\n",
    "dataset_1_jet_foc = \"C:/Users/May/Desktop/SURA24/datasets/1/cmapjet_focused\"\n",
    "dataset_1_jet_f2 = \"C:/Users/May/Desktop/SURA24/datasets/1/cmapjet_f2\"\n",
    "dataset_1_jet_f3 = \"C:/Users/May/Desktop/SURA24/datasets/1/cmapjet_f3\"\n",
    "\n",
    "dataset_indoor_1_jet = \"C:/Users/May/Desktop/SURA24/datasets/Indoor Images/1/cmapjet\"\n",
    "dataset_indoor_1 = \"C:/Users/May/Desktop/SURA24/datasets/Indoor Images/1\"\n",
    "dataset_8 = \"C:/Users/May/Desktop/SURA24/datasets/8\"\n",
    "dataset_8_jet = \"C:/Users/May/Desktop/SURA24/datasets/8/cmapjet\"\n",
    "dataset_8_brg = \"C:/Users/May/Desktop/SURA24/datasets/8/cmapbrg\"\n",
    "dataset_8_gray = \"C:/Users/May/Desktop/SURA24/datasets/8/cmapgray\"\n",
    "dataset_3 = \"C:/Users/May/Desktop/SURA24/datasets/3\"\n",
    "dataset_3_jet = \"C:/Users/May/Desktop/SURA24/datasets/3/cmapjet\"\n",
    "dataset_3_brg = \"C:/Users/May/Desktop/SURA24/datasets/3/cmapbrg\"\n",
    "dataset_4 = \"C:/Users/May/Desktop/SURA24/datasets/4\"\n",
    "dataset_4_jet = \"C:/Users/May/Desktop/SURA24/datasets/4/cmapjet\"\n",
    "dataset_4_brg = \"C:/Users/May/Desktop/SURA24/datasets/4/cmapbrg\"\n",
    "dataset_4_gray = \"C:/Users/May/Desktop/SURA24/datasets/4/cmapgray\"\n",
    "dataset_5 = \"C:/Users/May/Desktop/SURA24/datasets/5\"\n",
    "dataset_5_jet = \"C:/Users/May/Desktop/SURA24/datasets/5/cmapjet\"\n",
    "dataset_5_brg = \"C:/Users/May/Desktop/SURA24/datasets/5/cmapbrg\"\n",
    "dataset_5_gray = \"C:/Users/May/Desktop/SURA24/datasets/5/cmapgray\"\n",
    "dataset_16 = \"C:/Users/May/Desktop/SURA24/datasets/16\"\n",
    "dataset_16_jet = \"C:/Users/May/Desktop/SURA24/datasets/16/cmapjet\"\n",
    "dataset_16_brg = \"C:/Users/May/Desktop/SURA24/datasets/16/cmapbrg\"\n",
    "dataset_16_gray = \"C:/Users/May/Desktop/SURA24/datasets/16/cmapgray\"\n",
    "synthetic_1 = \"C:/Users/May/Desktop/SURA24/datasets/1/output_crops_jpg\"\n",
    "synthetic_8 = \"C:/Users/May/Desktop/SURA24/datasets/8/output_crops_jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17cd846-de33-4a22-b981-87d7697b7e23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffcf0dbf-67a2-4d95-982c-f178bdeed100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adopted from imutils library (https://github.com/jrosebr1/imutils/)\n",
    "def grab_contours(cnts): \n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts\n",
    "\n",
    "# this function returns a cropped version of the stiched image which doesnot contain black borders\n",
    "# Note: I have not considered all the edge cases here\n",
    "def improve_stitching_result(im):\n",
    "    img = im.copy()\n",
    "    im[np.where((im==[0,0,0]).all(axis=2))] = [255,255,255]\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 250, 255, 0)\n",
    "\n",
    "    # Find contours based on OpenCV version\n",
    "    contours = None\n",
    "    hierarchy = None\n",
    "    if cv2.__version__.startswith('3.'):\n",
    "        im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    elif cv2.__version__.startswith('4.'):\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        raise NotImplementedError(\"OpenCV version not supported\")\n",
    "\n",
    "    if contours is not None and len(contours) != 0:\n",
    "        # find the biggest contour (c) by the area\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        return img[0:y+h, 0:x+w, :]\n",
    "\n",
    "    # Handle case where no valid contours are found\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe1b3c5-a0cd-4e98-a465-9dfe555eaba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_black_borders(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Binary mask where white pixels represent non-black areas\n",
    "    _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get the bounding box of the largest contour\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        for cnt in contours:\n",
    "            x_, y_, w_, h_ = cv2.boundingRect(cnt)\n",
    "            x = min(x, x_)\n",
    "            y = min(y, y_)\n",
    "            w = max(w, w_)\n",
    "            h = max(h, h_)\n",
    "        \n",
    "        # Crop the image to the bounding box\n",
    "        cropped = image[y:y+h, x:x+w]\n",
    "        return cropped\n",
    "    else:\n",
    "        # If no contours were found, return the original image\n",
    "        return image\n",
    "\n",
    "def display_update(img1_orig, img2_orig, result):\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img1_orig, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Stitched Image\")\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(img2_orig, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Next Image\")\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Stitched Result\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2da862-1112-4bb1-b63f-ba923999f42b",
   "metadata": {},
   "source": [
    "#### Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d106a90-ce3f-4dd9-aa8d-4b4d60146b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(img1, img2, int, dir):\n",
    "\n",
    "    img1_orig = cv2.imread(img1)\n",
    "    img2_orig = cv2.imread(img2)\n",
    "    result = None\n",
    "    result_path = None\n",
    "\n",
    "    begin = time.perf_counter()\n",
    "\n",
    "    img1 = cv2.cvtColor(img1_orig, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2_orig, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Creating a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Finding keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Creating BFMatcher object\n",
    "    if des1 is not None and des2 is not None:\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good_matches = []\n",
    "        for m_n in matches:\n",
    "            if len(m_n) == 2:\n",
    "                m, n = m_n\n",
    "                if m.distance / n.distance < 0.8:\n",
    "                    good_matches.append((m.trainIdx, m.queryIdx))\n",
    "        \n",
    "        kp1 = np.float32([kp.pt for kp in kp1])\n",
    "        kp2 = np.float32([kp.pt for kp in kp2])\n",
    "\n",
    "        reprojThresh = 4.0\n",
    "        if len(good_matches) > 4:\n",
    "            pts1 = np.float32([kp1[i] for (_, i) in good_matches])\n",
    "            pts2 = np.float32([kp2[i] for (i, _) in good_matches])\n",
    "\n",
    "            H, status = cv2.findHomography(pts1, pts2, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "            try: \n",
    "                result = cv2.warpPerspective(img1_orig, H, (img1_orig.shape[1] + img2_orig.shape[1], max(img1_orig.shape[0], img2_orig.shape[0])))\n",
    "                result[0:img2_orig.shape[0], 0:img2_orig.shape[1]] = img2_orig\n",
    "                \n",
    "                result = improve_stitching_result(result)\n",
    "                result = crop_black_borders(result)\n",
    "    \n",
    "                # display_update(img1_orig, img2_orig, result)\n",
    "                \n",
    "            except:\n",
    "                print(\"Not enough good matches were found this iteration; skipped\")\n",
    "\n",
    "        else: \n",
    "            print(\"Not enough good matches were found.\")\n",
    "            \n",
    "    else: \n",
    "        print(\"No keypoints detected.\")\n",
    "        good_matches = None\n",
    "\n",
    "    if (result is not None): \n",
    "        try:\n",
    "           os.makedirs(dir)\n",
    "        except FileExistsError:\n",
    "           pass\n",
    "        result_path = f\"{dir}/{int}.JPG\"\n",
    "        cv2.imwrite(result_path, result)\n",
    "    return (good_matches, result_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbd3483-ec97-44bd-a25d-51ed38796cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a simulated \"ground truth\" image by applying the RGB \n",
    "# image transformations to their corresponding thermal images\n",
    "def ground_truth(img1, img2, ther1, ther2, int, dir):\n",
    "\n",
    "    img1_orig = cv2.imread(img1)\n",
    "    img2_orig = cv2.imread(img2)\n",
    "    ther1_orig = cv2.imread(ther1)\n",
    "    ther2_orig = cv2.imread(ther2)\n",
    "    result = None\n",
    "    result_path = None\n",
    "\n",
    "    begin = time.perf_counter()\n",
    "\n",
    "    img1 = cv2.cvtColor(img1_orig, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2_orig, cv2.COLOR_BGR2GRAY)\n",
    "    ther1 = cv2.cvtColor(ther1_orig, cv2.COLOR_BGR2GRAY)\n",
    "    ther2 = cv2.cvtColor(ther2_orig, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Creating a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Finding keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Creating BFMatcher object\n",
    "    if des1 is not None and des2 is not None:\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good_matches = []\n",
    "        for m_n in matches:\n",
    "            if len(m_n) == 2:\n",
    "                m, n = m_n\n",
    "                if m.distance / n.distance < 0.8:\n",
    "                    good_matches.append((m.trainIdx, m.queryIdx))\n",
    "        \n",
    "        kp1 = np.float32([kp.pt for kp in kp1])\n",
    "        kp2 = np.float32([kp.pt for kp in kp2])\n",
    "\n",
    "        reprojThresh = 4.0\n",
    "        if len(good_matches) > 4:\n",
    "            pts1 = np.float32([kp1[i] for (_, i) in good_matches])\n",
    "            pts2 = np.float32([kp2[i] for (i, _) in good_matches])\n",
    "\n",
    "            H, status = cv2.findHomography(pts1, pts2, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "            try: \n",
    "                result = cv2.warpPerspective(ther1_orig, H, (ther1_orig.shape[1] + ther2_orig.shape[1], max(ther1_orig.shape[0], ther2_orig.shape[0])))\n",
    "                result[0:ther2_orig.shape[0], 0:ther2_orig.shape[1]] = ther2_orig\n",
    "                \n",
    "                result = improve_stitching_result(result)\n",
    "                result = crop_black_borders(result)\n",
    "    \n",
    "                # display_update(ther1_orig, ther2_orig, result)\n",
    "                \n",
    "            except:\n",
    "                print(\"Not enough good matches were found this iteration; skipped\")\n",
    "\n",
    "        else: \n",
    "            print(\"Not enough good matches were found.\")\n",
    "            \n",
    "    else: \n",
    "        print(\"No keypoints detected.\")\n",
    "        good_matches = None\n",
    "\n",
    "    if (result is not None): \n",
    "        try:\n",
    "           os.makedirs(dir)\n",
    "        except FileExistsError:\n",
    "           pass\n",
    "        result_path = f\"{dir}/{int}.JPG\"\n",
    "        cv2.imwrite(result_path, result)\n",
    "    return (good_matches, result_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1807dc-d9eb-4098-958c-ff968c767ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example useage \n",
    "\n",
    "# img1 = \"/datasets/1/20240611_070653_687_R.JPG\"\n",
    "# img2 = \"/datasets/1/20240611_070656_687_R.JPG\"\n",
    "# ther1 = \"/datasets/1/cmapjet/jet_0.JPG\"\n",
    "# ther2 = \"/datasets/1/cmapjet/jet_1.JPG\"\n",
    "# stitch(ther2, ther1, 0)\n",
    "# ground_truth(img2, img1, ther2, ther1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd4cb1-5db4-4f7d-9753-9a8f35327f6e",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) [year] [fullname]\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
